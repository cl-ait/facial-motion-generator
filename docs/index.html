<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="title" content="Facial Motion Generator - Audio-driven Real-time Facial Expression Generation">
  <meta name="description" content="A lightweight audio-driven facial expression generation system for 3D avatars. Real-time inference at 0.62ms/frame with 52-dimensional ARKit BlendShape output.">
  <meta name="keywords" content="facial expression, blendshape, audio-driven, real-time, 3D avatar, ARKit, deep learning, cross-attention">
  <meta name="author" content="Junki Ichikawa, Ryoko Tokuhisa">
  <meta name="robots" content="index, follow">
  <meta name="language" content="Japanese">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Aichi Institute of Technology / RIKEN">
  <meta property="og:title" content="Facial Motion Generator">
  <meta property="og:description" content="A lightweight audio-driven facial expression generation system for 3D avatars.">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="3Dアバターに適用可能な音声駆動型リアルタイム表情生成システム">
  <meta name="citation_author" content="Ichikawa, Junki">
  <meta name="citation_author" content="Tokuhisa, Ryoko">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="言語処理学会 第32回年次大会 (NLP2026)">

  <title>Facial Motion Generator - Audio-driven Real-time Facial Expression Generation</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Noto+Sans+JP:wght@400;500;700&display=swap" rel="stylesheet">

  <style>
    :root {
      --primary-color: #2563eb;
      --text-color: #1f2937;
      --bg-color: #ffffff;
      --section-bg: #f3f4f6;
      --border-color: #e5e7eb;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', 'Noto Sans JP', sans-serif;
      color: var(--text-color);
      line-height: 1.6;
      background: var(--bg-color);
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 0 20px;
    }

    /* Hero Section */
    .hero {
      padding: 60px 0 40px;
      text-align: center;
    }

    .hero h1 {
      font-size: 2.5rem;
      font-weight: 700;
      margin-bottom: 20px;
      color: var(--text-color);
    }

    .authors {
      font-size: 1.1rem;
      color: #4b5563;
      margin-bottom: 10px;
    }

    .authors a {
      color: var(--primary-color);
      text-decoration: none;
    }

    .affiliations {
      font-size: 0.95rem;
      color: #6b7280;
      margin-bottom: 25px;
    }

    .conference {
      display: inline-block;
      background: var(--primary-color);
      color: white;
      padding: 6px 16px;
      border-radius: 20px;
      font-size: 0.9rem;
      font-weight: 500;
      margin-bottom: 30px;
    }

    /* Links */
    .links {
      display: flex;
      justify-content: center;
      gap: 15px;
      flex-wrap: wrap;
      margin-bottom: 40px;
    }

    .btn {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 10px 20px;
      border-radius: 8px;
      text-decoration: none;
      font-weight: 500;
      font-size: 0.95rem;
      transition: all 0.2s;
    }

    .btn-primary {
      background: var(--text-color);
      color: white;
    }

    .btn-primary:hover {
      background: #374151;
    }

    .btn-secondary {
      background: white;
      color: var(--text-color);
      border: 1px solid var(--border-color);
    }

    .btn-secondary:hover {
      border-color: var(--primary-color);
      color: var(--primary-color);
    }

    /* Sections */
    section {
      padding: 50px 0;
    }

    section.alt {
      background: var(--section-bg);
    }

    h2 {
      font-size: 1.75rem;
      font-weight: 600;
      margin-bottom: 20px;
      text-align: center;
    }

    /* Abstract */
    .abstract {
      text-align: justify;
      max-width: 800px;
      margin: 0 auto;
    }

    /* Results Table */
    .results-table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
    }

    .results-table th,
    .results-table td {
      padding: 12px 15px;
      text-align: center;
      border-bottom: 1px solid var(--border-color);
    }

    .results-table th {
      background: var(--section-bg);
      font-weight: 600;
    }

    .results-table tr:hover {
      background: #f9fafb;
    }

    /* Architecture */
    .architecture {
      background: var(--section-bg);
      padding: 20px;
      border-radius: 8px;
      font-family: monospace;
      font-size: 0.9rem;
      overflow-x: auto;
      white-space: pre;
      line-height: 1.5;
    }

    /* BibTeX */
    .bibtex {
      background: var(--section-bg);
      padding: 20px;
      border-radius: 8px;
      font-family: monospace;
      font-size: 0.85rem;
      overflow-x: auto;
      white-space: pre-wrap;
      position: relative;
    }

    .copy-btn {
      position: absolute;
      top: 10px;
      right: 10px;
      padding: 6px 12px;
      background: white;
      border: 1px solid var(--border-color);
      border-radius: 4px;
      cursor: pointer;
      font-size: 0.8rem;
    }

    .copy-btn:hover {
      background: var(--section-bg);
    }

    /* Footer */
    footer {
      padding: 30px 0;
      text-align: center;
      font-size: 0.9rem;
      color: #6b7280;
      border-top: 1px solid var(--border-color);
    }

    footer a {
      color: var(--primary-color);
      text-decoration: none;
    }

    /* Responsive */
    @media (max-width: 600px) {
      .hero h1 {
        font-size: 1.75rem;
      }

      .links {
        flex-direction: column;
        align-items: center;
      }

      .btn {
        width: 100%;
        max-width: 250px;
        justify-content: center;
      }
    }
  </style>
</head>
<body>

  <main>
    <!-- Hero -->
    <section class="hero">
      <div class="container">
        <h1>Facial Motion Generator</h1>
        <p class="subtitle" style="font-size: 1.1rem; color: #4b5563; margin-bottom: 20px;">
          3Dアバターに適用可能な音声駆動型リアルタイム表情生成システム
        </p>

        <div class="authors">
          <span>市川淳貴<sup>1</sup></span>,
          <span>徳久良子<sup>1,2</sup></span>
        </div>

        <div class="affiliations">
          <sup>1</sup>愛知工業大学,
          <sup>2</sup>理化学研究所
        </div>

        <div class="conference">NLP2026</div>

        <div class="links">
          <a href="https://github.com/atsuki-ichikawa/facial-motion-generator" class="btn btn-primary">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
              <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
            </svg>
            Code
          </a>
          <a href="static/pdfs/paper.pdf" class="btn btn-secondary">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
              <path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"/>
            </svg>
            Paper
          </a>
        </div>
      </div>
    </section>

    <!-- Abstract -->
    <section class="alt">
      <div class="container">
        <h2>Abstract</h2>
        <div class="abstract">
          <p>
            近年、3Dアバターを介した対話が普及する一方、音声に同期した表情生成は遅延や実装依存が課題である。
            本研究では、音声のみから表情動作の制御値を逐次推定し、ローカルでリアルタイム動作する<strong>Facial Motion Generator</strong>を提案する。
            異なる音声特徴量と軽量なCross-Attentionモデルを用いた設計により、
            Audio2Face-3Dと比較して単一話者データでMAE（平均絶対誤差）を0.147→0.111に低減し、
            推論時間を0.62ms/frameへ高速化した。
          </p>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section>
      <div class="container">
        <h2>Results</h2>
        <table class="results-table">
          <thead>
            <tr>
              <th>Model</th>
              <th>MSE ↓</th>
              <th>MAE ↓</th>
              <th>Parameters</th>
              <th>Inference Time</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Audio2Face-3D</td>
              <td>0.074</td>
              <td>0.147</td>
              <td>181M</td>
              <td>21.5 ms/frame</td>
            </tr>
            <tr style="background: #eff6ff;">
              <td><strong>Facial Motion Generator (Ours)</strong></td>
              <td><strong>0.035</strong></td>
              <td><strong>0.111</strong></td>
              <td><strong>0.72M</strong></td>
              <td><strong>0.62 ms/frame</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- Architecture -->
    <section class="alt">
      <div class="container">
        <h2>Architecture</h2>
        <div class="architecture">音声入力 (16kHz, モノラル)
    ↓
┌─────────────────────────────────────┐
│ Audio Encoder                        │
│  ├── Log-mel特徴 (80dim × 7frames)  │
│  └── eGeMAPS特徴 (88dim)            │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ Cross-Attention                      │
│  Query: 52個のBlendShape埋め込み     │
│  Key/Value: 音響特徴                 │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ BlendShape MLP                       │
│  → 52次元出力 (ARKit互換)            │
└─────────────────────────────────────┘
    ↓
OSC出力 (30Hz)</div>
      </div>
    </section>

    <!-- BibTeX -->
    <section>
      <div class="container">
        <h2>Citation</h2>
        <div class="bibtex">
          <button class="copy-btn" onclick="copyBibtex()">Copy</button>
@inproceedings{ichikawa2026facial,
  title={3Dアバターに適用可能な音声駆動型リアルタイム表情生成システム},
  author={市川淳貴 and 徳久良子},
  booktitle={言語処理学会 第32回年次大会},
  year={2026}
}</div>
      </div>
    </section>

    <!-- Acknowledgments -->
    <section class="alt">
      <div class="container">
        <h2>Acknowledgments</h2>
        <p style="text-align: center;">
          本研究はNVIDIAが公開する
          <a href="https://huggingface.co/datasets/nvidia/Audio2Face-3D-Dataset-v1.0.0-claire" target="_blank">Audio2Face-3D Dataset</a>
          を使用しています。
        </p>
      </div>
    </section>
  </main>

  <footer>
    <div class="container">
      <p>
        © 2026 Junki Ichikawa, Ryoko Tokuhisa |
        <a href="https://github.com/atsuki-ichikawa/facial-motion-generator">GitHub</a> |
        Licensed under <a href="https://opensource.org/licenses/MIT">MIT License</a>
      </p>
    </div>
  </footer>

  <script>
    function copyBibtex() {
      const bibtex = document.querySelector('.bibtex').innerText.replace('Copy', '').trim();
      navigator.clipboard.writeText(bibtex).then(() => {
        const btn = document.querySelector('.copy-btn');
        btn.textContent = 'Copied!';
        setTimeout(() => btn.textContent = 'Copy', 2000);
      });
    }
  </script>

</body>
</html>
